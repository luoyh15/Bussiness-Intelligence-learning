{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thinking1: ALS都有哪些应用场景?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 稀疏矩阵的矩阵分解。\n",
    "- 矩阵维度大，需要并行化处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thinking2：ALS进行矩阵分解的时候，为什么可以并行化处理？**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "迭代公式:\n",
    "1. 固定Y优化X：$x_u=(YY^T+\\lambda I)^{-1}YR^T_u$\n",
    "2. 固定X优化Y: $y_i=(XX^T+\\lambda I)^{-1}XR_i$ \n",
    "\n",
    "从公式可以发现，计算单独一列$x_u$时，只和矩阵中的对应列有关$R_u$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thinking3: 梯度下降法中的批量梯度下降（BGD），随机梯度下降（SGD），和小批量梯度下降有什么区别（MBGD）**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BGD：对所有样本求解梯度，梯度方向准确，但计算成本高。\n",
    "- SGD：随机选择一个样本求解梯度，梯度方向不准确，但计算很快。\n",
    "- MBGD：折中方法，选取一批样本求解梯度，兼顾梯度方向准确性和计算成本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thinking4：你阅读过和推荐系统/计算广告/预测相关的论文么？有哪些论文是你比较推荐的，可以分享到微信群中**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本身不是这个专业的，所以没有阅读过，不过十分感兴趣，如果有好的论文会去阅读。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action1：对MovieLens数据集进行评分预测  工具：可以使用Surprise或者其他  说明使用的模型，及简要原理**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**读取数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "# 数据读取\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "data = Dataset.load_from_file('./L4-code/MovieLens/ratings.csv', reader=reader)\n",
    "train_set = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**用ALS进行BaselineOnly算法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE: 0.8633\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8631\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8646\n",
      "user: 196        item: 302        r_ui = 4.00   est = 4.00   {'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 4.20   {'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 4.20   {'was_impossible': False}\n",
      "K-fold mean predictions: 4.1331293669449245\n"
     ]
    }
   ],
   "source": [
    "from surprise import BaselineOnly\n",
    "# 定义K折交叉验证迭代器, K=3\n",
    "kf = KFold(n_splits=3)\n",
    "# 存储K个模型\n",
    "algos = []\n",
    "\n",
    "# BaselineOnly模型\n",
    "# ALS优化\n",
    "bsl_options = {'method': 'als','n_epochs': 5,'reg_u': 12,'reg_i': 5}\n",
    "# SGD优化\n",
    "#bsl_options = {'method': 'sgd','n_epochs': 5}\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo = BaselineOnly(bsl_options=bsl_options)\n",
    "    #algo = NormalPredictor()\n",
    "    algos.append(algo)\n",
    "    # 训练并预测\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    # 计算RMSE\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "\n",
    "# 需要预测的数据\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "# 输出uid对iid的预测结果\n",
    "preds = [algo.predict(uid, iid, r_ui=4, verbose=True).est for algo in algos]\n",
    "print('K-fold mean predictions:', sum(preds)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**用SGD进行BaselineOnly算法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "RMSE: 0.8743\n",
      "Estimating biases using sgd...\n",
      "RMSE: 0.8735\n",
      "Estimating biases using sgd...\n",
      "RMSE: 0.8758\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.86   {'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 4.04   {'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.99   {'was_impossible': False}\n",
      "K-fold mean predictions: 3.964278285335246\n"
     ]
    }
   ],
   "source": [
    "from surprise import BaselineOnly\n",
    "# 定义K折交叉验证迭代器, K=3\n",
    "kf = KFold(n_splits=3)\n",
    "# 存储K个模型\n",
    "algos = []\n",
    "\n",
    "# BaselineOnly模型\n",
    "# ALS优化\n",
    "# bsl_options = {'method': 'als','n_epochs': 5,'reg_u': 12,'reg_i': 5}\n",
    "# SGD优化\n",
    "bsl_options = {'method': 'sgd','n_epochs': 5}\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo = BaselineOnly(bsl_options=bsl_options)\n",
    "    #algo = NormalPredictor()\n",
    "    algos.append(algo)\n",
    "    # 训练并预测\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    # 计算RMSE\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "\n",
    "# 需要预测的数据\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "# 输出uid对iid的预测结果\n",
    "preds = [algo.predict(uid, iid, r_ui=4, verbose=True).est for algo in algos]\n",
    "print('K-fold mean predictions:', sum(preds)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**可以看到在本次测试中，SGD的准确度比ALS要低**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NomalPredictor算法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4322\n",
      "RMSE: 1.4316\n",
      "RMSE: 1.4332\n",
      "user: 196        item: 302        r_ui = 4.00   est = 5.00   {'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 5.00   {'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 2.82   {'was_impossible': False}\n",
      "K-fold mean predictions: 4.27334836259108\n"
     ]
    }
   ],
   "source": [
    "from surprise import NormalPredictor\n",
    "# 定义K折交叉验证迭代器, K=3\n",
    "kf = KFold(n_splits=3)\n",
    "# 存储K个模型\n",
    "algos = []\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo = NormalPredictor()\n",
    "    algos.append(algo)\n",
    "    # 训练并预测\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    # 计算RMSE\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "\n",
    "# 需要预测的数据\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "# 输出uid对iid的预测结果\n",
    "preds = [algo.predict(uid, iid, r_ui=4, verbose=True).est for algo in algos]\n",
    "print('K-fold mean predictions:', sum(preds)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNNBasic算法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9026\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9052\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9038\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.94   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.84   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.97   {'actual_k': 27, 'was_impossible': False}\n",
      "K-fold mean predictions: 3.9170069999300323\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "# 定义K折交叉验证迭代器, K=3\n",
    "kf = KFold(n_splits=3)\n",
    "# 存储K个模型\n",
    "algos = []\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo = KNNBasic() #use default setting\n",
    "    algos.append(algo)\n",
    "    # 训练并预测\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    # 计算RMSE\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "\n",
    "# 需要预测的数据\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "# 输出uid对iid的预测结果\n",
    "preds = [algo.predict(uid, iid, r_ui=4, verbose=True).est for algo in algos]\n",
    "print('K-fold mean predictions:', sum(preds)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN非常占内存，而且非常耗时**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNNBasic with item based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9618\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9612\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9612\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.95   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.47   {'actual_k': 40, 'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.67   {'actual_k': 40, 'was_impossible': False}\n",
      "K-fold mean predictions: 3.697036271529362\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "# 定义K折交叉验证迭代器, K=3\n",
    "kf = KFold(n_splits=3)\n",
    "# 存储K个模型\n",
    "algos = []\n",
    "\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo = KNNBasic(sim_options=sim_options)\n",
    "    algos.append(algo)\n",
    "    # 训练并预测\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    # 计算RMSE\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "\n",
    "# 需要预测的数据\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "# 输出uid对iid的预测结果\n",
    "preds = [algo.predict(uid, iid, r_ui=4, verbose=True).est for algo in algos]\n",
    "print('K-fold mean predictions:', sum(preds)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVD算法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8473\n",
      "RMSE: 0.8460\n",
      "RMSE: 0.8445\n",
      "user: 196        item: 302        r_ui = 4.00   est = 4.25   {'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 4.28   {'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 4.09   {'was_impossible': False}\n",
      "K-fold mean predictions: 4.202593266287534\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "# 定义K折交叉验证迭代器, K=3\n",
    "kf = KFold(n_splits=3)\n",
    "# 存储K个模型\n",
    "algos = []\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    # 低维矩阵维度100，迭代次数20\n",
    "    algo = SVD(n_factors=100, n_epochs=20)\n",
    "    algos.append(algo)\n",
    "    # 训练并预测\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    # 计算RMSE\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "\n",
    "# 需要预测的数据\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "# 输出uid对iid的预测结果\n",
    "preds = [algo.predict(uid, iid, r_ui=4, verbose=True).est for algo in algos]\n",
    "print('K-fold mean predictions:', sum(preds)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SlopeOne算法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8675\n",
      "RMSE: 0.8700\n",
      "RMSE: 0.8670\n",
      "user: 196        item: 302        r_ui = 4.00   est = 4.13   {'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 4.39   {'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 4.46   {'was_impossible': False}\n",
      "K-fold mean predictions: 4.3260530208506855\n"
     ]
    }
   ],
   "source": [
    "from surprise import SlopeOne\n",
    "# 定义K折交叉验证迭代器, K=3\n",
    "kf = KFold(n_splits=3)\n",
    "# 存储K个模型\n",
    "algos = []\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo = SlopeOne()\n",
    "    algos.append(algo)\n",
    "    # 训练并预测\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    # 计算RMSE\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "\n",
    "# 需要预测的数据\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "# 输出uid对iid的预测结果\n",
    "preds = [algo.predict(uid, iid, r_ui=4, verbose=True).est for algo in algos]\n",
    "print('K-fold mean predictions:', sum(preds)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CoClustering算法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8986\n",
      "RMSE: 0.8993\n",
      "RMSE: 0.8925\n",
      "user: 196        item: 302        r_ui = 4.00   est = 4.08   {'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.91   {'was_impossible': False}\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.89   {'was_impossible': False}\n",
      "K-fold mean predictions: 3.961027621013977\n"
     ]
    }
   ],
   "source": [
    "from surprise import CoClustering\n",
    "# 定义K折交叉验证迭代器, K=3\n",
    "kf = KFold(n_splits=3)\n",
    "# 存储K个模型\n",
    "algos = []\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    # 用户聚类数3， 商品聚类数3，迭代次数20\n",
    "    algo = CoClustering(n_cltr_u=3, n_cltr_i=3, n_epochs=20)\n",
    "    algos.append(algo)\n",
    "    # 训练并预测\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    # 计算RMSE\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "\n",
    "# 需要预测的数据\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "# 输出uid对iid的预测结果\n",
    "preds = [algo.predict(uid, iid, r_ui=4, verbose=True).est for algo in algos]\n",
    "print('K-fold mean predictions:', sum(preds)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action2: Paper Reading：Slope one predictors for online rating-based collaborative filtering. Daniel Lemire and Anna Maclachlan, 2007. http://arxiv.org/abs/cs/0702144.\n",
    "积累，总结笔记，自己的思考及idea**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope one算法\n",
    "简介：\n",
    "- 优点：实现简单，计算迅速，合理准确，支持在线查询和动态更新\n",
    "- 提出了三种Slope One算法\n",
    "\n",
    "鲁棒性好的CF算法的目标：\n",
    "1. 实现和维护简单\n",
    "2. 实时更新\n",
    "3. 高效访问\n",
    "4. 对新用户所需的打分数据少\n",
    "5. 准确且可解释\n",
    "\n",
    "**衡量两种商品‘受欢迎差异’的方法：两种商品平均评分的差值。**（确实十分简单）\n",
    "介绍了其他算法以做对比：\n",
    "- user based\n",
    "1. PER USER AVERAGE：直接以用户评分平均值作为评分\n",
    "2. BIAS FROM MEAN：用户评分平均值+此商品偏离平均分的分数\n",
    "- item based\n",
    "3. ADJUSTED COSINE ITEMBASED：商品评分=两商品之间的相似度$\\times$该用户对其他商品的评分的线性回归, 再做一下归一\n",
    "- user based also memory based(计算用户相似性非常耗时，而且对新用户准确性较差）\n",
    "4. The PEARSON Reference Scheme：用户评分平均值+此商品偏离平均分的归一化分数，此处的归一化系数是两用户的相关性\n",
    "\n",
    "The SLOPE ONE Scheme：\n",
    "- 两商品的偏差：$dev_{j,i}=\\sum\\limits_{u\\in S_{j,i}(\\chi)} \\frac{u_j-u_i}{card(S_{j,i}(\\chi)}$(**就是一个差值求和取平均**）\n",
    "- 预测：$P(u)_j=\\frac{1}{card(R_j)}\\sum\\limits_{i\\in R_j}(dev_{j,i}+u_i)$\n",
    " - $R_j$: 用户评分过的商品且该商品也被其他用户评分过\n",
    " - **简单来说就是用用户评分过的商品加上两商品的偏差来预测被预测的商品。**\n",
    "- 简化一下：$P^{S1}(u)_j=\\bar{u}+\\frac{1}{card(R_j)}\\sum\\limits_{i\\in R_j}dev_{j,i}$\n",
    "\n",
    "The WEIGHTED SLOPE ONE Scheme:\n",
    "- 加权。不同商品被评分的次数代表了该商品在预测时所占的权重\n",
    "- $P^{wS1}(u)_j=\\frac{\\sum_{i\\in R_j}(dev_{j,i}+u_i)c_{j,i}}{\\sum_{i\\in R_j}c_{j,i}}$.\n",
    "- $c_{j,i}=card(S_{j,i}(\\chi))$ ：代表同时评价了$i,j$商品的用户数目\n",
    "\n",
    "The BI-POLAR SLOPE ONE Scheme：\n",
    "- 两极化。**将商品根据用户评分的平均分，分为喜欢和不喜欢两级。再用WEIGHTED SLOPE ONE分别在喜欢和不喜欢的商品集里做预测，再加权两个预测分数。**\n",
    "- 两商品的偏差，这里不同的是只在用户都喜欢$i,j$时才计算在内：$$dev^{like}_{j,i}=\\sum\\limits_{u\\in S^{like}_{j,i}(\\chi)} \\frac{u_j-u_i}{card(S^{like}_{j,i}(\\chi)}$$\n",
    "- $$P^{bpS1}(u)_j=\\frac{\\sum_{i\\in R^{like}_j} p^{like}_{j,i}c^{like}_{j,i}+\\sum_{i\\in R^{dislike}_j} p^{dislike}_{j,i}c^{dislike}_{j,i}}{\\sum_{i\\in R^{like}_j} c^{like}_{j,i}+\\sum_{i\\in R^{dislike}_j} c^{dislike}_{j,i}}$$\n",
    "- $c^{like}_{j,i}=card(S^{like}_{j,i}), c^{dislike}_{j,i}=card(S^{dislike}_{j,i})$\n",
    "- **物以类聚，人以群分**\n",
    " - **对商品做了分类，同时被某一用户喜欢的商品更加相近，用相近的商品来预测更加准确.**\n",
    " - **对用户做了分类，同时喜欢\\不喜欢$(i,j)$商品的用户喜好更加接近, 用相同喜好的用户来预测更加准确。**\n",
    " - **一点改进想法：既然是分类之后进行预测，不妨先对用户和商品进行聚类，再进行预测求平均。**\n",
    " \n",
    "测试结果：\n",
    "- 衡量标准：MAE\n",
    "- WEIGHTED SLOPE ONE 比 SLOPE ONE 提升1%，BI-POLAR SLOPE ONE 提升1.5~2%\n",
    "- BI-POLAR SLOPE ONE 和 Person 相当，但效率更高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action3：设计你自己的句子生成器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "遇上史莱姆，勇士损失1000。\n",
      "遇上史莱姆，勇士损失50。\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# 定语从句语法\n",
    "grammar = '''\n",
    "前进 => 遇上 怪物  ， 掉血 。 \n",
    "掉血 => 勇士 损失 血量\n",
    "怪物 => 史莱姆 | 蝙蝠 | 骷髅 | 法师 | 魔龙 \n",
    "血量 => 10 | 20 | 50 | 100 | 1000\n",
    "'''\n",
    "\n",
    "# 得到语法字典\n",
    "def getGrammarDict(gram, linesplit = \"\\n\", gramsplit = \"=>\"):\n",
    "    #定义字典\n",
    "    result = {}\n",
    "\n",
    "    for line in gram.split(linesplit):\n",
    "        # 去掉首尾空格后，如果为空则退出\n",
    "        if not line.strip(): \n",
    "            continue\n",
    "        expr, statement = line.split(gramsplit)\n",
    "        result[expr.strip()] = [i.split() for i in statement.split(\"|\")]\n",
    "    #print(result)\n",
    "    return result\n",
    "\n",
    "# 生成句子\n",
    "def generate(gramdict, target):\n",
    "    if target not in gramdict: \n",
    "        return target\n",
    "    find = random.choice(gramdict[target])\n",
    "    return ''.join(generate(gramdict, t) for t in find)\n",
    "\n",
    "gramdict = getGrammarDict(grammar)\n",
    "print(generate(gramdict,\"前进\"))\n",
    "print(generate(gramdict,\"前进\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
